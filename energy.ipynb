{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1 import"
      ],
      "metadata": {
        "id": "s1bXEMK12x5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import argparse\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "pHSpl9B82z5R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBrzD0r43FJU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 log"
      ],
      "metadata": {
        "id": "Al1S26eV3Km3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s: %(filename)s[%(lineno)d]: %(message)s\",\n",
        "    datefmt=\"%m-%d %H:%M:%S\")\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "wlog = logger.info"
      ],
      "metadata": {
        "id": "nhMEZBOG3M5H"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 hyper-parameter"
      ],
      "metadata": {
        "id": "kU7twfRA20VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(\"Diffusion Recovery Likelihood\")\n",
        "parser.add_argument(\"--dataset\", type=str, default=\"cifar10\", choices=[\"cifar10\", \"svhn\", \"cifar100\"])\n",
        "parser.add_argument(\"--data_root\", type=str, default=\"./data\")\n",
        "# optimization\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=128)\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=250)\n",
        "parser.add_argument(\"--warmup_iters\", type=int, default=1000, help=\"number of iters to linearly increase learning rate, if -1 then no warmmup\")\n",
        "parser.add_argument(\"--sigma\", type=float, default=3e-2, help=\"stddev of gaussian noise to add to input, .03 works but .1 is more stable\")\n",
        "parser.add_argument(\"--weight_decay\", type=float, default=5e-4)\n",
        "\n",
        "parser.add_argument(\"--width\", type=int, default=10, help=\"WRN width parameter\")\n",
        "parser.add_argument(\"--depth\", type=int, default=28, help=\"WRN depth parameter\")\n",
        "parser.add_argument(\"--model\", type=str, default='wrnte', help='wrnte, wrntesn')\n",
        "parser.add_argument(\"--norm\", type=str, default=None, choices=[None, \"none\", \"batch\", \"instance\", \"layer\", \"act\", 'td'], help=\"norm to add to weights, none works fine\")\n",
        "\n",
        "parser.add_argument(\"--n_valid\", type=int, default=0)\n",
        "parser.add_argument(\"--log_dir\", type=str, default='./runs/DRL')\n",
        "parser.add_argument(\"--resume\", type=str, default=None)\n",
        "\n",
        "parser.add_argument(\"--novis\", action=\"store_true\", help=\"\")\n",
        "parser.add_argument(\"--debug\", action=\"store_true\", help=\"\")\n",
        "parser.add_argument(\"--exp_name\", type=str, default=\"DIS\", help=\"exp name, for description\")\n",
        "parser.add_argument(\"--gpu-id\", type=str, default=\"0\")\n",
        "# args = parser.parse_args()\n",
        "args, unparsed = parser.parse_known_args()"
      ],
      "metadata": {
        "id": "BADAQu3a25il"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_id"
      ],
      "metadata": {
        "id": "k3BDKXgp4cdF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "args.seed = 1\n",
        "args.device = device"
      ],
      "metadata": {
        "id": "ViNmPNe55M_y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters of diffusion recovery likelihood\n",
        "args.img_sz = 32\n",
        "args.num_diffusion_timesteps = 6\n",
        "args.num_timesteps = 6\n",
        "args.opt = 'sgd'\n",
        "args.ma_decay = 0.999\n",
        "args.noise_scale = 1.0\n",
        "args.mcmc_num_steps = 30\n",
        "args.mcmc_step_size_b_square = 2e-4\n",
        "args.debug = False\n",
        "\n",
        "args.pid = os.getpid()"
      ],
      "metadata": {
        "id": "4tm_jvlb5NDb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logfile = os.path.join('runs', 'DRL', \"%d_%s.log\" % (args.pid, args.model))\n",
        "args.log_dir = 'runs/DRL/%d' % args.pid\n",
        "print(\"log dir is %s\" % args.log_dir)\n",
        "os.makedirs(args.log_dir, exist_ok=True)\n",
        "fh = logging.FileHandler(logfile, mode='w')\n",
        "fh.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d]: %(message)s\")\n",
        "fh.setFormatter(formatter)\n",
        "logger.addHandler(fh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij8T88oY5e3U",
        "outputId": "837d45c0-1710-4153-ccfd-056827259f29"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log dir is runs/DRL/777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 util"
      ],
      "metadata": {
        "id": "Kv1K6RAX70Ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 数据获取"
      ],
      "metadata": {
        "id": "i96AZXgN8DoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch as t\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "class DataSubset(Dataset):\n",
        "    def __init__(self, base_dataset, inds=None, size=-1):\n",
        "        self.base_dataset = base_dataset\n",
        "        if inds is None:\n",
        "            inds = np.random.choice(list(range(len(base_dataset))), size, replace=False)\n",
        "        self.inds = inds\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        base_ind = self.inds[index]\n",
        "        return self.base_dataset[base_ind]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inds)"
      ],
      "metadata": {
        "id": "oQRKy7t089_6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrt(x):\n",
        "    return int(t.sqrt(t.Tensor([x])))\n",
        "\n",
        "\n",
        "def plot(p, x):\n",
        "    return tv.utils.save_image(t.clamp(x, -1, 1), p, normalize=True, nrow=sqrt(x.size(0)))\n",
        "\n",
        "\n",
        "def makedirs(dirname):\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, save, epoch):\n",
        "    if not os.path.exists(save):\n",
        "        os.makedirs(save)\n",
        "    filename = os.path.join(save, 'checkpt-%04d.pth' % epoch)\n",
        "    torch.save(state, filename)"
      ],
      "metadata": {
        "id": "hQNQ9mHA9kSi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data"
      ],
      "metadata": {
        "id": "ZKqwEb3A9q0f"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as tr\n",
        "import torchvision as tv\n",
        "\n",
        "def get_data(args):\n",
        "    mean, std = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "    if args.dataset == \"svhn\":\n",
        "        transform_train = tr.Compose(\n",
        "            [tr.Pad(4, padding_mode=\"reflect\"),\n",
        "             tr.RandomCrop(32),\n",
        "             tr.ToTensor(),\n",
        "             tr.Normalize(mean, std),\n",
        "             # lambda x: x + args.sigma * t.randn_like(x)\n",
        "             ]\n",
        "        )\n",
        "        transform_px = tr.Compose(\n",
        "            [tr.ToTensor(),\n",
        "             tr.Normalize(mean, std),\n",
        "             ]\n",
        "        )\n",
        "    else:\n",
        "        transform_train = tr.Compose(\n",
        "            [tr.Pad(4, padding_mode=\"reflect\"),\n",
        "             tr.RandomCrop(32),\n",
        "             tr.RandomHorizontalFlip(),\n",
        "             tr.ToTensor(),\n",
        "             tr.Normalize(mean, std),\n",
        "             # lambda x: x + args.sigma * t.randn_like(x)\n",
        "             ]\n",
        "        )\n",
        "        transform_px = tr.Compose(\n",
        "            [tr.RandomHorizontalFlip(),\n",
        "             tr.ToTensor(),\n",
        "             tr.Normalize(mean, std),\n",
        "             ]\n",
        "        )\n",
        "    transform_test = tr.Compose(\n",
        "        [tr.ToTensor(),\n",
        "         tr.Normalize(mean, std),\n",
        "         ]\n",
        "    )\n",
        "    def dataset_fn(train, transform):\n",
        "        if args.dataset == \"cifar10\":\n",
        "            args.n_classes = 10\n",
        "            return tv.datasets.CIFAR10(root=args.data_root, transform=transform, download=True, train=train)\n",
        "        elif args.dataset == \"cifar100\":\n",
        "            args.n_classes = 100\n",
        "            return tv.datasets.CIFAR100(root=args.data_root, transform=transform, download=True, train=train)\n",
        "        else:\n",
        "            args.n_classes = 10\n",
        "            return tv.datasets.SVHN(root=args.data_root, transform=transform, download=True, split=\"train\" if train else \"test\")\n",
        "\n",
        "    # get all training inds\n",
        "    full_train = dataset_fn(True, transform_train)\n",
        "    all_inds = list(range(len(full_train)))\n",
        "    # set seed\n",
        "    np.random.seed(args.seed)\n",
        "    # shuffle\n",
        "    np.random.shuffle(all_inds)\n",
        "\n",
        "    # 缩减训练集大小，保留10%的数据\n",
        "    reduction_ratio = 0.2\n",
        "    train_size = int(len(all_inds) * reduction_ratio)\n",
        "    reduced_train_inds = all_inds[:train_size]\n",
        "\n",
        "    # 验证集的划分\n",
        "    if args.n_valid > args.n_classes:\n",
        "        valid_inds, train_inds = reduced_train_inds[:args.n_valid], reduced_train_inds[args.n_valid:]\n",
        "    else:\n",
        "        valid_inds, train_inds = [], reduced_train_inds\n",
        "\n",
        "\n",
        "    # # seperate out validation set\n",
        "    # if args.n_valid > args.n_classes:\n",
        "    #     valid_inds, train_inds = all_inds[:args.n_valid], all_inds[args.n_valid:]\n",
        "    # else:\n",
        "    #     valid_inds, train_inds = [], all_inds\n",
        "\n",
        "    train_inds = np.array(train_inds)\n",
        "    train_labeled_inds = train_inds\n",
        "\n",
        "    dset_train = DataSubset(dataset_fn(True, transform_px), inds=train_inds)\n",
        "    dset_train_labeled = DataSubset(dataset_fn(True, transform_train), inds=train_labeled_inds)\n",
        "    dset_valid = DataSubset(dataset_fn(True, transform_test), inds=valid_inds)\n",
        "\n",
        "    num_workers = 0 if args.debug else 4\n",
        "    dload_train = DataLoader(dset_train, batch_size=args.batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "    label_bs = 128\n",
        "    dload_train_labeled = DataLoader(dset_train_labeled, batch_size=label_bs, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "    dload_train = cycle(dload_train)\n",
        "    dset_test = dataset_fn(False, transform_test)\n",
        "    dload_valid = DataLoader(dset_valid, batch_size=100, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "    dload_test = DataLoader(dset_test, batch_size=100, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "    return dload_train, dload_train_labeled, dload_valid, dload_test"
      ],
      "metadata": {
        "id": "XD33xE467zgh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA:\n",
        "    def __init__(self, mu):\n",
        "        self.mu = mu\n",
        "        self.shadow = {}\n",
        "\n",
        "    def register(self, name, val):\n",
        "        self.shadow[name] = val.clone()\n",
        "\n",
        "    def __call__(self, name, x):\n",
        "        assert name in self.shadow\n",
        "        new_average = self.mu * x + (1.0 - self.mu) * self.shadow[name]\n",
        "        self.shadow[name] = new_average.clone()\n",
        "        return new_average"
      ],
      "metadata": {
        "id": "Ru7Ysb7P7zx6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uj6bs0ul-jc-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 模型"
      ],
      "metadata": {
        "id": "fLNnF1JA-kFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from models.wideresnet_te import Wide_ResNet as WResNet\n",
        "# from models.wrn_te_sn import Wide_ResNet as WResNetSN"
      ],
      "metadata": {
        "id": "dVS9EjOv-nqm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#norm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class ConditionalInstanceNorm2dPlus(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, bias=True):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.bias = bias\n",
        "        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n",
        "        if bias:\n",
        "            self.embed = nn.Embedding(num_classes, num_features * 3)\n",
        "            self.embed.weight.data[:, :2 * num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
        "            self.embed.weight.data[:, 2 * num_features:].zero_()  # Initialise bias at 0\n",
        "        else:\n",
        "            self.embed = nn.Embedding(num_classes, 2 * num_features)\n",
        "            self.embed.weight.data.normal_(1, 0.02)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        means = torch.mean(x, dim=(2, 3))\n",
        "        m = torch.mean(means, dim=-1, keepdim=True)\n",
        "        v = torch.var(means, dim=-1, keepdim=True)\n",
        "        means = (means - m) / (torch.sqrt(v + 1e-5))\n",
        "        h = self.instance_norm(x)\n",
        "\n",
        "        if self.bias:\n",
        "            gamma, alpha, beta = self.embed(y).chunk(3, dim=-1)\n",
        "            h = h + means[..., None, None] * alpha[..., None, None]\n",
        "            out = gamma.view(-1, self.num_features, 1, 1) * h + beta.view(-1, self.num_features, 1, 1)\n",
        "        else:\n",
        "            gamma, alpha = self.embed(y).chunk(2, dim=-1)\n",
        "            h = h + means[..., None, None] * alpha[..., None, None]\n",
        "            out = gamma.view(-1, self.num_features, 1, 1) * h\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalActNorm(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.num_classes = num_classes\n",
        "        self.embed = nn.Embedding(num_classes, num_features * 2)\n",
        "        self.embed.weight.data.zero_()\n",
        "        self.init = False\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        if self.init:\n",
        "            scale, bias = self.embed(y).chunk(2, dim=-1)\n",
        "            return x * scale[:, :, None, None] + bias[:, :, None, None]\n",
        "        else:\n",
        "            m, v = torch.mean(x, dim=(0, 2, 3)), torch.var(x, dim=(0, 2, 3))\n",
        "            std = torch.sqrt(v + 1e-5)\n",
        "            scale_init = 1. / std\n",
        "            bias_init = -1. * m / std\n",
        "            self.embed.weight.data[:, :self.num_features] = scale_init[None].repeat(self.num_classes, 1)\n",
        "            self.embed.weight.data[:, self.num_features:] = bias_init[None].repeat(self.num_classes, 1)\n",
        "            self.init = True\n",
        "            return self(x, y)\n",
        "\n",
        "\n",
        "logabs = lambda x: torch.log(torch.abs(x))\n",
        "\n",
        "\n",
        "class ActNorm(nn.Module):\n",
        "    def __init__(self, in_channel, logdet=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loc = nn.Parameter(torch.zeros(1, in_channel, 1, 1))\n",
        "        self.scale = nn.Parameter(torch.ones(1, in_channel, 1, 1))\n",
        "\n",
        "        self.register_buffer('initialized', torch.tensor(0, dtype=torch.uint8))\n",
        "        self.logdet = logdet\n",
        "\n",
        "    def initialize(self, input):\n",
        "        with torch.no_grad():\n",
        "            flatten = input.permute(1, 0, 2, 3).contiguous().view(input.shape[1], -1)\n",
        "            mean = (\n",
        "                flatten.mean(1)\n",
        "                .unsqueeze(1)\n",
        "                .unsqueeze(2)\n",
        "                .unsqueeze(3)\n",
        "                .permute(1, 0, 2, 3)\n",
        "            )\n",
        "            std = (\n",
        "                flatten.std(1)\n",
        "                .unsqueeze(1)\n",
        "                .unsqueeze(2)\n",
        "                .unsqueeze(3)\n",
        "                .permute(1, 0, 2, 3)\n",
        "            )\n",
        "\n",
        "            self.loc.data.copy_(-mean)\n",
        "            self.scale.data.copy_(1 / (std + 1e-6))\n",
        "\n",
        "    def forward(self, input):\n",
        "        _, _, height, width = input.shape\n",
        "\n",
        "        if self.initialized.item() == 0:\n",
        "            self.initialize(input)\n",
        "            self.initialized.fill_(1)\n",
        "\n",
        "        log_abs = logabs(self.scale)\n",
        "\n",
        "        logdet = height * width * torch.sum(log_abs)\n",
        "\n",
        "        if self.logdet:\n",
        "            return self.scale * (input + self.loc), logdet\n",
        "\n",
        "        else:\n",
        "            return self.scale * (input + self.loc)\n",
        "\n",
        "    def reverse(self, output):\n",
        "        return output / self.scale - self.loc\n",
        "\n",
        "\n",
        "class ContinuousConditionalActNorm(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        del num_classes\n",
        "        self.num_features = num_features\n",
        "        self.embed = nn.Sequential(nn.Linear(1, 256),\n",
        "                                   nn.ELU(inplace=True),\n",
        "                                   nn.Linear(256, 256),\n",
        "                                   nn.ELU(inplace=True),\n",
        "                                   nn.Linear(256, self.num_features*2),\n",
        "                                   )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        scale, bias = self.embed(y.unsqueeze(-1)).chunk(2, dim=-1)\n",
        "        return x * scale[:, :, None, None] + bias[:, :, None, None]\n",
        "\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_norm(n_filters, norm, T=6):\n",
        "    if norm is None or norm.lower() == 'none':\n",
        "        return Identity()\n",
        "    elif norm == \"batch\":\n",
        "        return nn.BatchNorm2d(n_filters, momentum=0.9)\n",
        "    elif norm == \"instance\":\n",
        "        return nn.InstanceNorm2d(n_filters, affine=True)\n",
        "    elif norm == \"layer\":\n",
        "        return nn.GroupNorm(1, n_filters)\n",
        "    elif norm == \"act\":\n",
        "        return ActNorm(n_filters, False)\n",
        "    else:\n",
        "        return Identity()"
      ],
      "metadata": {
        "id": "qFllGhII-n5T"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### basic wideresnet"
      ],
      "metadata": {
        "id": "jM044GSP_qRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "\"\"\"\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
        "        init.constant(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant(m.weight, 1)\n",
        "        init.constant(m.bias, 0)\n",
        "\n",
        "\n",
        "class wide_basic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1, norm=None, leak=.2):\n",
        "        super(wide_basic, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.lrelu = nn.LeakyReLU(leak)\n",
        "        self.bn1 = get_norm(in_planes, norm)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = Identity() if dropout_rate == 0.0 else nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = get_norm(planes, norm)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.dropout(self.conv1(self.lrelu(out)))\n",
        "        out = self.bn2(out)\n",
        "        out = self.conv2(self.lrelu(out))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Wide_ResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, num_classes=10, input_channels=3,\n",
        "                 sum_pool=False, norm=None, leak=.2, dropout_rate=0.0):\n",
        "        super(Wide_ResNet, self).__init__()\n",
        "        self.leak = leak\n",
        "        self.in_planes = 16\n",
        "        self.sum_pool = sum_pool\n",
        "        self.norm = norm\n",
        "        self.lrelu = nn.LeakyReLU(leak)\n",
        "        self.n_classes = num_classes\n",
        "\n",
        "        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth - 4) // 6\n",
        "        k = widen_factor\n",
        "\n",
        "        print('| Wide-Resnet %dx%d' % (depth, k))\n",
        "        nStages = [16, 16 * k, 32 * k, 64 * k]\n",
        "\n",
        "        self.conv1 = conv3x3(input_channels, nStages[0])\n",
        "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1, leak=leak)\n",
        "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2, leak=leak)\n",
        "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2, leak=leak)\n",
        "        self.bn1 = get_norm(nStages[3], self.norm)\n",
        "        self.last_dim = nStages[3]\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride, leak=0.2):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride, leak=leak, norm=self.norm))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, logits=False, feature=True):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.lrelu(self.bn1(out))\n",
        "        if self.sum_pool:\n",
        "            out = out.view(out.size(0), out.size(1), -1).sum(2)\n",
        "        else:\n",
        "            if self.n_classes > 100:\n",
        "                out = F.adaptive_avg_pool2d(out, 1)\n",
        "            else:\n",
        "                out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        if logits:\n",
        "            out = self.linear(out)\n",
        "        return out\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "3dXEUgrq_C-G",
        "outputId": "d40483f6-85d5-4dc8-c329-59a2b4af39ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef conv_init(m):\\n    classname = m.__class__.__name__\\n    if classname.find('Conv') != -1:\\n        init.xavier_uniform(m.weight, gain=np.sqrt(2))\\n        init.constant(m.bias, 0)\\n    elif classname.find('BatchNorm') != -1:\\n        init.constant(m.weight, 1)\\n        init.constant(m.bias, 0)\\n\\n\\nclass wide_basic(nn.Module):\\n    def __init__(self, in_planes, planes, dropout_rate, stride=1, norm=None, leak=.2):\\n        super(wide_basic, self).__init__()\\n        self.norm = norm\\n        self.lrelu = nn.LeakyReLU(leak)\\n        self.bn1 = get_norm(in_planes, norm)\\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\\n        self.dropout = Identity() if dropout_rate == 0.0 else nn.Dropout(p=dropout_rate)\\n        self.bn2 = get_norm(planes, norm)\\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\\n\\n        self.shortcut = nn.Sequential()\\n        if stride != 1 or in_planes != planes:\\n            self.shortcut = nn.Sequential(\\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\\n            )\\n\\n    def forward(self, x):\\n        out = self.bn1(x)\\n        out = self.dropout(self.conv1(self.lrelu(out)))\\n        out = self.bn2(out)\\n        out = self.conv2(self.lrelu(out))\\n        out += self.shortcut(x)\\n\\n        return out\\n\\n\\nclass Wide_ResNet(nn.Module):\\n    def __init__(self, depth, widen_factor, num_classes=10, input_channels=3,\\n                 sum_pool=False, norm=None, leak=.2, dropout_rate=0.0):\\n        super(Wide_ResNet, self).__init__()\\n        self.leak = leak\\n        self.in_planes = 16\\n        self.sum_pool = sum_pool\\n        self.norm = norm\\n        self.lrelu = nn.LeakyReLU(leak)\\n        self.n_classes = num_classes\\n\\n        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\\n        n = (depth - 4) // 6\\n        k = widen_factor\\n\\n        print('| Wide-Resnet %dx%d' % (depth, k))\\n        nStages = [16, 16 * k, 32 * k, 64 * k]\\n\\n        self.conv1 = conv3x3(input_channels, nStages[0])\\n        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1, leak=leak)\\n        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2, leak=leak)\\n        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2, leak=leak)\\n        self.bn1 = get_norm(nStages[3], self.norm)\\n        self.last_dim = nStages[3]\\n        self.linear = nn.Linear(nStages[3], num_classes)\\n\\n    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride, leak=0.2):\\n        strides = [stride] + [1] * (num_blocks - 1)\\n        layers = []\\n\\n        for stride in strides:\\n            layers.append(block(self.in_planes, planes, dropout_rate, stride, leak=leak, norm=self.norm))\\n            self.in_planes = planes\\n\\n        return nn.Sequential(*layers)\\n\\n    def forward(self, x, logits=False, feature=True):\\n        out = self.conv1(x)\\n        out = self.layer1(out)\\n        out = self.layer2(out)\\n        out = self.layer3(out)\\n        out = self.lrelu(self.bn1(out))\\n        if self.sum_pool:\\n            out = out.view(out.size(0), out.size(1), -1).sum(2)\\n        else:\\n            if self.n_classes > 100:\\n                out = F.adaptive_avg_pool2d(out, 1)\\n            else:\\n                out = F.avg_pool2d(out, 8)\\n        out = out.view(out.size(0), -1)\\n        if logits:\\n            out = self.linear(out)\\n        return out\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### te utils"
      ],
      "metadata": {
        "id": "P5whi3SJAzGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def get_timestep_embedding(timesteps, embedding_dim: int):\n",
        "    \"\"\"\n",
        "    From Fairseq.\n",
        "    Build sinusoidal embeddings.\n",
        "    This matches the implementation in tensor2tensor, but differs slightly\n",
        "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
        "    \"\"\"\n",
        "    assert len(timesteps.shape) == 1  # and timesteps.dtype == torch.int32\n",
        "\n",
        "    half_dim = embedding_dim // 2\n",
        "    emb = math.log(10000) / (half_dim - 1)\n",
        "    emb = torch.exp(torch.arange(0, half_dim) * -emb).to(timesteps.device)\n",
        "    emb = torch.matmul(1.0 * timesteps.reshape(-1, 1), emb.reshape(1, -1))\n",
        "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
        "    if embedding_dim % 2 == 1:  # zero pad\n",
        "        # emb = torch.cat([emb, torch.zeros([num_embeddings, 1])], axis=1)\n",
        "        emb = F.pad(emb, [0, 1, 0, 0])\n",
        "    assert list(emb.shape) == [timesteps.shape[0], embedding_dim]\n",
        "    return emb"
      ],
      "metadata": {
        "id": "8xt-XWAOAfX6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model te"
      ],
      "metadata": {
        "id": "5h5YUacyA7G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from .wideresnet import get_norm, conv3x3, Identity\n",
        "# from .te_utils import get_timestep_embedding\n",
        "\n",
        "\n",
        "class wide_basic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1, norm=None, leak=.2):\n",
        "        super(wide_basic, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.lrelu = nn.LeakyReLU(leak)\n",
        "        self.bn1 = get_norm(in_planes, norm)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = Identity() if dropout_rate == 0.0 else nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = get_norm(planes, norm)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.temb_dense = nn.Linear(512, planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, temb = x\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(self.lrelu(out))\n",
        "        if temb is not None:\n",
        "            # add in timestep embedding\n",
        "            temp_o = self.lrelu(self.temb_dense(temb))\n",
        "            b, l = temp_o.shape\n",
        "            out += temp_o.view(b, l, 1, 1)\n",
        "\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.conv2(self.lrelu(out))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out, temb\n",
        "\n",
        "\n",
        "class Wide_ResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, num_classes=10, input_channels=3, sum_pool=False, norm=None, leak=.2, dropout_rate=0.0):\n",
        "        super(Wide_ResNet, self).__init__()\n",
        "        self.leak = leak\n",
        "        self.in_planes = 16\n",
        "        self.sum_pool = sum_pool\n",
        "        self.norm = norm\n",
        "        self.lrelu = nn.LeakyReLU(leak)\n",
        "        self.n_classes = num_classes\n",
        "\n",
        "        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth - 4) // 6\n",
        "        k = widen_factor\n",
        "\n",
        "        print('| Wide-Resnet %dx%d, time embedding' % (depth, k))\n",
        "        nStages = [16, 16 * k, 32 * k, 64 * k]\n",
        "\n",
        "        self.layer_one_out = None\n",
        "        self.conv1 = conv3x3(input_channels, nStages[0])\n",
        "        # self.layer_one = self.conv1\n",
        "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1, leak=leak)\n",
        "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2, leak=leak)\n",
        "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2, leak=leak)\n",
        "        self.bn1 = get_norm(nStages[3], self.norm)\n",
        "        self.last_dim = nStages[3]\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "        self.temb_dense_0 = nn.Linear(128, 512)\n",
        "        self.temb_dense_1 = nn.Linear(512, 512)\n",
        "        self.temb_dense_2 = nn.Linear(512, nStages[3])\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride, leak=0.2):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride, leak=leak, norm=self.norm))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, t, logits=False, feature=True):\n",
        "        out = self.conv1(x)\n",
        "        assert x.dtype == torch.float32\n",
        "        if isinstance(t, int) or len(t.shape) == 0:\n",
        "            t = torch.ones(x.shape[0], dtype=torch.int64, device=x.device) * t\n",
        "        temb = get_timestep_embedding(t, 128)\n",
        "        temb = self.temb_dense_0(temb)\n",
        "        temb = self.temb_dense_1(self.lrelu(temb))\n",
        "\n",
        "        out, _ = self.layer1([out, temb])\n",
        "        out, _ = self.layer2([out, temb])\n",
        "        out, _ = self.layer3([out, temb])\n",
        "        out = self.lrelu(self.bn1(out))\n",
        "        if self.sum_pool:\n",
        "            out = out.view(out.size(0), out.size(1), -1).sum(2)\n",
        "        else:\n",
        "            if self.n_classes > 100:\n",
        "                out = F.adaptive_avg_pool2d(out, 1)\n",
        "            else:\n",
        "                out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        temb = self.temb_dense_2(self.lrelu(temb))\n",
        "        out *= temb\n",
        "        if logits:\n",
        "            out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4Y9RaY52AfwC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "QyLbIx3fBGe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ch_mult = (1, 2, 2, 2)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# net = Wide_ResNet(28, 10, norm='batch', dropout_rate=0).to(device)\n",
        "# x = torch.randn([64, 3, 32, 32]).to(device)\n",
        "# t = torch.randint(size=[64], high=6).to(device)\n",
        "# output = net(x, t)\n",
        "# print(output.shape)"
      ],
      "metadata": {
        "id": "8ou7Fc9ZAf5J"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5  recovery likelihood"
      ],
      "metadata": {
        "id": "jJHuwTP8EX7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sigma_schedule(*, beta_start, beta_end, num_diffusion_timesteps):\n",
        "    \"\"\"\n",
        "    Get the noise level schedule\n",
        "    :param beta_start: begin noise level\n",
        "    :param beta_end: end noise level\n",
        "    :param num_diffusion_timesteps: number of timesteps\n",
        "    :return:\n",
        "    -- sigmas: sigma_{t+1}, scaling parameter of epsilon_{t+1}\n",
        "    -- a_s: sqrt(1 - sigma_{t+1}^2), scaling parameter of x_t\n",
        "    \"\"\"\n",
        "    betas = np.linspace(beta_start, beta_end, 1000, dtype=np.float64)\n",
        "    betas = np.append(betas, 1.)\n",
        "    assert isinstance(betas, np.ndarray)\n",
        "    betas = betas.astype(np.float64)\n",
        "    assert (betas > 0).all() and (betas <= 1).all()\n",
        "    sqrt_alphas = np.sqrt(1. - betas)\n",
        "    temp = np.concatenate([np.arange(num_diffusion_timesteps) * (1000 // ((num_diffusion_timesteps - 1) * 2)), [999]])\n",
        "    idx = temp.astype(np.int32)\n",
        "    a_s = np.concatenate(\n",
        "        [[np.prod(sqrt_alphas[: idx[0] + 1])],\n",
        "         np.asarray([np.prod(sqrt_alphas[idx[i - 1] + 1: idx[i] + 1]) for i in np.arange(1, len(idx))])])\n",
        "    sigma = np.sqrt(1 - a_s ** 2)\n",
        "\n",
        "    return sigma, a_s"
      ],
      "metadata": {
        "id": "95cj6ngoEyzg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unsorted_segment_mean(values, index, num_segments):\n",
        "    ones = torch.ones_like(values)\n",
        "    sums = torch.zeros(num_segments, device=values.device).scatter_add_(0, index, values)\n",
        "    counts = torch.zeros(num_segments, device=values.device).scatter_add_(0, index, ones)\n",
        "    return sums / counts\n"
      ],
      "metadata": {
        "id": "rK4EBt_AHAFI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecoveryLikelihood(nn.Module):\n",
        "    def __init__(self, model, args):\n",
        "        super(RecoveryLikelihood, self).__init__()\n",
        "        self.args = args\n",
        "        self.num_timesteps = args.num_diffusion_timesteps\n",
        "\n",
        "        sigmas, a_s = get_sigma_schedule(beta_start=0.0001, beta_end=0.02, num_diffusion_timesteps=self.num_timesteps)\n",
        "        self.sigmas = torch.FloatTensor(sigmas).to(args.device)\n",
        "        self.a_s = torch.FloatTensor(a_s).to(args.device)\n",
        "\n",
        "        self.a_s_cum = torch.FloatTensor(np.cumprod(a_s)).to(args.device)\n",
        "        self.sigmas_cum = torch.sqrt(1 - self.a_s_cum ** 2)\n",
        "        self.a_s_prev = self.a_s.clone()\n",
        "        self.a_s_prev[-1] = 1\n",
        "        self.is_recovery = torch.ones(self.num_timesteps + 1).to(args.device)\n",
        "        self.is_recovery[-1] = 0\n",
        "        self.device = args.device\n",
        "\n",
        "        # self.net = net_res_temb2(name='net', ch=128, ch_mult=ch_mult, num_res_blocks=self.args.num_res_blocks, attn_resolutions=(16,))\n",
        "        # self.net = Wide_ResNet(28, 10, norm='batch', dropout_rate=0).to(args.device)\n",
        "        self.net = model\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract(a, t, x_shape, device):\n",
        "        \"\"\"\n",
        "        Extract some coefficients at specified timesteps,\n",
        "        then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
        "        \"\"\"\n",
        "        if isinstance(t, int) or len(t.shape) == 0:\n",
        "            t = torch.ones(x_shape[0], dtype=torch.int64, device=device) * t\n",
        "        bs, = t.shape\n",
        "        assert x_shape[0] == bs\n",
        "        out = a[t]\n",
        "        # out = tf.gather(tf.convert_to_tensor(a, dtype=tf.float32), t)\n",
        "        # print(out.shape, t.shape, bs)\n",
        "        assert list(out.shape) == [bs]\n",
        "        return torch.reshape(out, [bs] + ((len(x_shape) - 1) * [1]))\n",
        "\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        \"\"\"\n",
        "        Diffuse the data (t == 0 means diffused for 1 step)\n",
        "        \"\"\"\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start)\n",
        "        assert noise.shape == x_start.shape\n",
        "        x_t = self._extract(self.a_s_cum, t, x_start.shape, self.args.device) * x_start + \\\n",
        "              self._extract(self.sigmas_cum, t, x_start.shape, self.args.device) * noise\n",
        "\n",
        "        return x_t\n",
        "\n",
        "    def q_sample_pairs(self, x_start, t):\n",
        "        \"\"\"\n",
        "        Generate a pair of disturbed images for training\n",
        "        :param x_start: x_0\n",
        "        :param t: time step t\n",
        "        :return: x_t, x_{t+1}\n",
        "        \"\"\"\n",
        "        noise = torch.randn_like(x_start)\n",
        "        x_t = self.q_sample(x_start, t)\n",
        "        x_t_plus_one = self._extract(self.a_s, t + 1, x_start.shape, self.args.device) * x_t + \\\n",
        "                       self._extract(self.sigmas, t + 1, x_start.shape, self.args.device) * noise\n",
        "\n",
        "        return x_t, x_t_plus_one\n",
        "\n",
        "    def q_sample_progressive(self, x_0):\n",
        "        \"\"\"\n",
        "        Generate a full sequence of disturbed images\n",
        "        \"\"\"\n",
        "        x_preds = []\n",
        "        for t in range(self.num_timesteps + 1):\n",
        "            t_now = torch.ones([x_0.shape[0]], dtype=torch.int32, device=self.args.device) * t\n",
        "            x = self.q_sample(x_0, t_now)\n",
        "            x_preds.append(x)\n",
        "        x_preds = torch.stack(x_preds, axis=0)\n",
        "\n",
        "        return x_preds\n",
        "\n",
        "    # === Training loss ===\n",
        "    def training_losses(self, x_pos, x_neg, t):\n",
        "        \"\"\"\n",
        "        Training loss calculation\n",
        "        \"\"\"\n",
        "        a_s = self._extract(self.a_s_prev, t + 1, x_pos.shape, self.args.device)\n",
        "        y_pos = a_s * x_pos\n",
        "        y_neg = a_s * x_neg\n",
        "        pos_f = self.net(y_pos, t).sum(dim=1)\n",
        "        neg_f = self.net(y_neg, t).sum(dim=1)\n",
        "        loss = - (pos_f - neg_f)\n",
        "\n",
        "        loss_scale = 1.0 / (self.sigmas[t + 1] / self.sigmas[1])\n",
        "        loss = loss_scale * loss\n",
        "\n",
        "        # loss_ts = torch.math.unsorted_segment_mean(torch.abs(loss), t, self.num_timesteps)\n",
        "        loss_ts = unsorted_segment_mean(torch.abs(loss), t, self.num_timesteps).detach()\n",
        "        f_ts = unsorted_segment_mean(pos_f, t, self.num_timesteps).detach()\n",
        "\n",
        "        return loss.mean(), loss_ts, f_ts\n",
        "\n",
        "    def log_prob(self, y, t, tilde_x, b0, sigma, is_recovery):\n",
        "        logits = self.net(y, t)\n",
        "\n",
        "        return logits.sum(dim=1) / torch.reshape(b0, [-1]) - torch.sum((y - tilde_x) ** 2 / 2 / sigma ** 2 * is_recovery, dim=[1, 2, 3])\n",
        "\n",
        "    def grad_f(self, y, t, tilde_x, b0, sigma, is_recovery):\n",
        "        log_p_y = self.log_prob(y, t, tilde_x, b0, sigma, is_recovery)\n",
        "        grad_y = torch.autograd.grad(log_p_y.sum(), [y], retain_graph=True)[0]\n",
        "        # grad_y = torch.clamp(grad_y, -1, 1)\n",
        "        return grad_y, log_p_y\n",
        "\n",
        "    # === Sampling ===\n",
        "    def p_sample_langevin(self, tilde_x, t):\n",
        "        \"\"\"\n",
        "        Langevin sampling function\n",
        "        \"\"\"\n",
        "        sigma = self._extract(self.sigmas, t + 1, tilde_x.shape, self.args.device)\n",
        "        sigma_cum = self._extract(self.sigmas_cum, t, tilde_x.shape, self.args.device)\n",
        "        is_recovery = self._extract(self.is_recovery, t + 1, tilde_x.shape, self.args.device)\n",
        "        a_s = self._extract(self.a_s_prev, t + 1, tilde_x.shape, self.args.device)\n",
        "\n",
        "        c_t_square = sigma_cum / self.sigmas_cum[0]\n",
        "        step_size_square = c_t_square * self.args.mcmc_step_size_b_square * sigma ** 2\n",
        "\n",
        "        # y = torch.identity(tilde_x)\n",
        "        y = torch.autograd.Variable(tilde_x, requires_grad=True).to(self.args.device)\n",
        "        is_accepted_summary = torch.zeros(y.shape[0], dtype=torch.float32, device=self.args.device)\n",
        "\n",
        "        grad_y, log_p_y = self.grad_f(y, t, tilde_x, step_size_square, sigma, is_recovery)\n",
        "\n",
        "        for _ in range(self.args.mcmc_num_steps):\n",
        "            noise = torch.randn_like(y)\n",
        "            y_new = y + 0.5 * step_size_square * grad_y + torch.sqrt(step_size_square) * noise * self.args.noise_scale\n",
        "\n",
        "            grad_y_new, log_p_y_new = self.grad_f(y_new, t, tilde_x, step_size_square, sigma, is_recovery)\n",
        "            y, grad_y, log_p_y = y_new, grad_y_new, log_p_y_new\n",
        "\n",
        "        is_accepted_summary = 1.0 * is_accepted_summary / self.args.mcmc_num_steps\n",
        "        is_accepted_summary = torch.mean(is_accepted_summary)\n",
        "\n",
        "        x = y / a_s\n",
        "\n",
        "        values = torch.norm(torch.reshape(x, [x.shape[0], -1]) - torch.reshape(tilde_x, [tilde_x.shape[0], -1]), dim=1)\n",
        "        disp = unsorted_segment_mean(values, t, self.num_timesteps)\n",
        "        return x, disp, is_accepted_summary\n",
        "\n",
        "    def p_sample_progressive(self, noise):\n",
        "        \"\"\"\n",
        "        Sample a sequence of images with the sequence of noise levels\n",
        "        \"\"\"\n",
        "        num = noise.shape[0]\n",
        "        x_neg_t = noise\n",
        "        x_neg = torch.zeros([self.args.num_diffusion_timesteps, num, 3, self.args.img_sz, self.args.img_sz], device=self.device)\n",
        "        x_neg = torch.cat([x_neg, torch.unsqueeze(noise, axis=0)], dim=0)\n",
        "        is_accepted_summary = 0.\n",
        "\n",
        "        for t in range(self.args.num_diffusion_timesteps - 1, -1, -1):\n",
        "            t_v = torch.tensor(t).to(self.device)\n",
        "\n",
        "            x_neg_t, _, is_accepted = self.p_sample_langevin(x_neg_t, t_v)\n",
        "            is_accepted_summary = is_accepted_summary + is_accepted\n",
        "            x_neg_t = torch.reshape(x_neg_t, [num, 3, self.args.img_sz, self.args.img_sz])\n",
        "            insert_mask = t == torch.arange(self.args.num_diffusion_timesteps + 1, device=self.device)\n",
        "            insert_mask = torch.reshape(insert_mask, [-1, *([1] * len(noise.shape))])\n",
        "            x_neg = insert_mask * torch.unsqueeze(x_neg_t, axis=0) + (~ insert_mask) * x_neg\n",
        "        is_accepted_summary = is_accepted_summary / self.args.num_diffusion_timesteps * 1.0\n",
        "        return x_neg, is_accepted_summary\n",
        "\n"
      ],
      "metadata": {
        "id": "O5_4lPVV_DCi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 buffer"
      ],
      "metadata": {
        "id": "i4IDHHpUIxtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7** 训练类"
      ],
      "metadata": {
        "id": "B7sa_mLx26MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_from_scratch(diff_model, num_images, epoch, arg):\n",
        "    noise = torch.randn(size=[25, 3, 32, 32]).to(arg.device)\n",
        "    num_batch = int(np.ceil(num_images / 25))\n",
        "\n",
        "    buffer = []\n",
        "    for k in tqdm(range(num_batch)):\n",
        "        x_neg, _ = diff_model.p_sample_progressive(noise)\n",
        "        x_neg = x_neg[0].detach()\n",
        "        buffer.append(x_neg)\n",
        "        if k == 0 or k == 10:\n",
        "            print(x_neg)\n",
        "            plot('{}/img_{}_{:>06d}.png'.format(arg.log_dir, epoch, k), x_neg)\n",
        "    buffer = torch.cat(buffer)\n",
        "    return buffer"
      ],
      "metadata": {
        "id": "f93QUaGJPmBK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Task.eval_buffer import eval_is_fid\n",
        "\n",
        "class DRLTrainer:\n",
        "    def __init__(self, arg):\n",
        "        self.args = arg\n",
        "        self.epoch_loss = 0\n",
        "        self.diffusion = None\n",
        "        self.diffusion_ema = None\n",
        "        self.ema = None\n",
        "        self.f_p = None\n",
        "\n",
        "    def get_pred_by_freq(self, x, last=False):\n",
        "        include_xpred_freq = max(1, self.args.num_diffusion_timesteps // 10)\n",
        "        idx = torch.LongTensor(np.arange(self.args.num_diffusion_timesteps // include_xpred_freq + 1) * include_xpred_freq)\n",
        "        if last:\n",
        "            idx[-1] = idx[-1] - 1\n",
        "        return x[idx]\n",
        "\n",
        "    def train_a_batch(self, x, optimizer, epoch, i):\n",
        "        t = torch.randint(size=[x.shape[0]], high=self.args.num_timesteps, device=device)\n",
        "\n",
        "        x_pos, x_neg = self.diffusion.q_sample_pairs(x, t)\n",
        "        x_neg, disp, is_accepted = self.diffusion.p_sample_langevin(x_neg, t)\n",
        "        loss, _, f_p = self.diffusion.training_losses(x_pos, x_neg, t)\n",
        "        self.epoch_loss += loss.item()\n",
        "        self.f_p += f_p\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # self.ema.apply(self.diffusion)\n",
        "        if i % 10 == 0:\n",
        "            wlog('%d, [epoch:%d, iter:%d] Loss: %.03f' % (self.args.pid, epoch, i, self.epoch_loss / (i + 1)))\n",
        "            f_ts = self.get_pred_by_freq(self.f_p, last=True)\n",
        "            f_ts = \", \".join([\"\".join(str(np.around(aa.cpu().numpy(), 3))) for aa in f_ts])\n",
        "            wlog('Positive Energy T ={:s}'.format(f_ts))\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self):\n",
        "        arg = self.args\n",
        "\n",
        "        arg.n_classes = 10\n",
        "        # datasets\n",
        "        label_loader, train_loader, valid_loader, test_loader = get_data(arg)\n",
        "\n",
        "        # model\n",
        "        if arg.model == \"wrnte\":\n",
        "            net =Wide_ResNet(arg.depth, arg.width, num_classes=arg.n_classes, norm=None)\n",
        "            net_ema = Wide_ResNet(arg.depth, arg.width, num_classes=arg.n_classes, norm=None)\n",
        "        else:\n",
        "            net = Wide_ResNet(arg.depth, arg.width, num_classes=arg.n_classes, norm=None)\n",
        "            net_ema = Wide_ResNet(arg.depth, arg.width, num_classes=arg.n_classes, norm=None)\n",
        "\n",
        "\n",
        "        print('Model parameters: {:.2f}M'.format(sum(p.numel() for p in net.parameters()) / 1e6))\n",
        "        if arg.resume is not None:\n",
        "            pt = torch.load(args.resume)\n",
        "            net.load_state_dict(pt)\n",
        "\n",
        "        net = net.to(args.device)\n",
        "\n",
        "        if args.lr > 0.01:\n",
        "            optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=5e-4, momentum=0.9)\n",
        "        else:\n",
        "            optimizer = optim.Adam(net.parameters(), lr=args.lr, betas=[.9, .999], weight_decay=5e-4)\n",
        "\n",
        "\n",
        "        self.diffusion = RecoveryLikelihood(net, arg)\n",
        "\n",
        "        self.ema = EMA(mu=arg.ma_decay)\n",
        "\n",
        "        best_acc = 0\n",
        "        cur_iter = 0\n",
        "        cur_lr = arg.lr\n",
        "\n",
        "        for epoch in range(args.n_epochs):\n",
        "            self.epoch_loss = 0\n",
        "            self.f_p = 0\n",
        "            if epoch in [120, 160, 200, 230]:\n",
        "                cur_lr *= 0.2\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] *= 0.2\n",
        "                wlog(\"Learning rate decay %f\" % cur_lr)\n",
        "\n",
        "            net.train()\n",
        "            for i, data in tqdm(enumerate(train_loader)):\n",
        "                if cur_iter <= args.warmup_iters:\n",
        "                    lr = args.lr * cur_iter / float(args.warmup_iters)\n",
        "                    for param_group in optimizer.param_groups:\n",
        "                        param_group['lr'] = lr\n",
        "\n",
        "                x_p_d, _ = label_loader.__next__()\n",
        "                x_p_d = x_p_d.to(device)\n",
        "\n",
        "                loss = self.train_a_batch(x_p_d, optimizer, epoch, i)\n",
        "                cur_iter += 1\n",
        "                if abs(loss) > 1000:\n",
        "                    print(\"diverge Epoch {} iter {}\".format(epoch, i))\n",
        "                    return\n",
        "\n",
        "            metrics = {}\n",
        "            i += 1  # in case of debugging\n",
        "            if epoch % 5 == 0:\n",
        "                buffer = generate_from_scratch(self.diffusion, 1000, epoch=epoch, arg=arg)\n",
        "                inc_score, std, fid = eval_is_fid(buffer, arg, eval='all')\n",
        "                wlog(\"Inception score of {} with std of {}\".format(inc_score, std))\n",
        "                wlog(\"FID of score {}\".format(fid))\n",
        "                metrics['Gen/IS'] = inc_score\n",
        "                metrics['Gen/FID'] = fid\n",
        "                metrics['Loss/EBM'] = self.epoch_loss / i\n",
        "                metrics['Loss/T0'] = self.f_p[0] / i\n",
        "                metrics['Loss/T2'] = self.f_p[2] / i\n",
        "                metrics['Loss/T4'] = self.f_p[4] / i\n",
        "                metrics['Loss/T6'] = self.f_p[5] / i\n",
        "\n",
        "            torch.save(net.state_dict(), \"./runs/DRL/%s/%s_last.pth\" % (str(self.args.pid), str(arg.model)))\n",
        "            if epoch % 10 == 0:\n",
        "                torch.save(net.state_dict(), \"./runs/DRL/%s/%s_%d.pth\" % (str(self.args.pid), str(arg.model), epoch))\n"
      ],
      "metadata": {
        "id": "wtjLVjV-2696"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = DRLTrainer(args)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "Lrb1PemW-g3U",
        "outputId": "ac0fe6bf-726f-4550-c8b3-ccd39090a624"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "| Wide-Resnet 28x10, time embedding\n",
            "| Wide-Resnet 28x10, time embedding\n",
            "Model parameters: 39.43M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]INFO:root:777, [epoch:0, iter:0] Loss: -0.016\n",
            "INFO:root:Positive Energy T =-0.216, -0.178, -0.151, -0.113, -0.126, -0.215, -0.215\n",
            "10it [03:28, 20.85s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-07150a0a3f34>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDRLTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-eaebb2d8cc3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mx_p_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_p_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_a_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mcur_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-eaebb2d8cc3c>\u001b[0m in \u001b[0;36mtrain_a_batch\u001b[0;34m(self, x, optimizer, epoch, i)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_sample_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_accepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_sample_langevin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-b6f93a6bd053>\u001b[0m in \u001b[0;36mp_sample_langevin\u001b[0;34m(self, tilde_x, t)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep_size_square\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size_square\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mgrad_y_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p_y_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilde_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size_square\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_recovery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_y_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p_y_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-b6f93a6bd053>\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(self, y, t, tilde_x, b0, sigma, is_recovery)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilde_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_recovery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilde_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_recovery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mgrad_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# grad_y = torch.clamp(grad_y, -1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-b6f93a6bd053>\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, y, t, tilde_x, b0, sigma, is_recovery)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilde_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_recovery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtilde_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mis_recovery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-8efc4d95f345>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, t, logits, feature)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mtemb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestep_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mtemb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemb_dense_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mtemb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemb_dense_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-7282142699d0>\u001b[0m in \u001b[0;36mget_timestep_embedding\u001b[0;34m(timesteps, embedding_dim)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mhalf_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhalf_dim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qafN45aKCVP3",
        "outputId": "6df294ad-170d-4c42-dd5d-1251cf1cef9c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VYfqMpLICdhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}